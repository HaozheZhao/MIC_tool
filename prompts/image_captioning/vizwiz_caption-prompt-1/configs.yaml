dataset:
  name: "vizwiz_caption"
  subset_size: -1
  prompt: 1
  data_path: "./data/vizwiz_caption"
  modalities: ["image", "text"]
  types: ["image", "answer"]
  url:
    vision: "https://drive.google.com/drive/folders/1MBBhlkP83VMKS2Qe0SmFfzkHhMpIG5wf?usp=sharing"
    language: "https://drive.google.com/drive/folders/1MBBhlkP83VMKS2Qe0SmFfzkHhMpIG5wf?usp=sharing"
    prompt: "https://arxiv.org/pdf/2110.08484.pdf"
task:
  name: "image_captioning"
  template_path: "./prompts/image_captioning/vizwiz_caption-prompt-1/template.json"
  example_path: "./prompts/image_captioning/vizwiz_caption-prompt-1/examples.json"
  definition: ""
  path: "https://coco.org/"
  input: ["text", "image"]
  output: ["answer"]
metadata:
  path: "./metadata/all_task.json"
output:
  path: "./tasks/"
contact:
  contributor: ["Anonymous"]