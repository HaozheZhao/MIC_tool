dataset:
  name: "textvqa"
  subset_size: -1
  data_path: "./data/textvqa"
  prompt: 1
  modalities: ["image", "text"]
  types: ["image", "question"]
  url:
    vision: "https://drive.google.com/drive/folders/1MBBhlkP83VMKS2Qe0SmFfzkHhMpIG5wf?usp=sharing"
    language: "https://drive.google.com/drive/folders/1MBBhlkP83VMKS2Qe0SmFfzkHhMpIG5wf?usp=sharing"
    prompt: "https://arxiv.org/pdf/1811.00491.pdf"
task:
  name: "visual_question_answering"
  template_path: "./prompts/visual_question_answering/textvqa-prompt-1/template.json"
  example_path: "./prompts/visual_question_answering/textvqa-prompt-1/examples.json"
  definition: ""
  path: ""
  input: ["text", "image"]
  output: ["answer"]
metadata:
  path: "./metadata/all_task.json"
output:
  path: "./tasks/"
contact:
  contributor: ["Anonymous"]